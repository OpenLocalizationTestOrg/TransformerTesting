<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="7-listening-for-incoming-data.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7-listening-for-incoming-data.85c570a02df8c4fb4c2e53b1c6cb23c765fccf9e.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bcd4f8e9ad653100ec873077bd5a5eeee979a151</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\convert-speech-to-text\includes\7-listening-for-incoming-data.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Working with the Speech Translation API <ph id="ph1">`Recognize`</ph> method starts with creating and opening an authorized WebSocket connection to the Speech Translation API endpoint.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Because a real-time, conversational translation process is <bpt id="p1">_</bpt>ongoing<ept id="p1">_</ept>, the Speech service uses the concept of "listening" to a socket for incoming translation data.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>The process of listening</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Reading streams</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Listening for incoming translation data means evaluating streams or byte arrays returned by the Speech service in a constant, consistent fashion, as if you were engaging in a real human conversation.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For example, in C#, listening for an initial incoming translation might look like this:</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>In the prior example, a <ph id="ph1">`DataReader`</ph> object is used to continually interrogate the returned values based on stream or byte-array buffer length.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>The Speech Translation API <ph id="ph1">`Translate`</ph> method does all the converting, cleans up the data, translates speech to text, and responds with the final (or interim) translated content.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Initial return values</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Because speech translation is a multistep process, initial data from a listening event comes in as a well-formatted JSON payload, just like it does for most other methods in the Azure Cognitive Services suite of APIs:</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>But after the text is translated, listening for translated text to be synthesized looks like any scenario where you're working with a stream or byte array instead of human-readable text:</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Platform-specific code for playing the resulting synthesized audio stream has been removed for brevity.</source>
        </trans-unit></group></body></file></xliff>