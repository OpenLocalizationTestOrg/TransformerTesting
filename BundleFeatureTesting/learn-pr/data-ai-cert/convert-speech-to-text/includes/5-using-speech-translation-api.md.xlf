<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="5-using-speech-translation-api.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5-using-speech-translation-api.c9cd35e267f29d28c2a3c748a2c1f38e750bc1e0.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">64dd0bd217c3396bbee95e52fbc19c70e790f6cc</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\convert-speech-to-text\includes\5-using-speech-translation-api.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Translating speech with the Speech Translation API involves two steps:</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Creating and opening an authorized WebSocket request to the subscription endpoint.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Processing the information returned from the call.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`Translate`</ph> is the method you use to translate speech.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>When making a request to <ph id="ph1">`Translate`</ph>, you provide parameters to tell the service the source language, the target language, and the voice selection.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>For example, a request to the <ph id="ph1">`Translate`</ph> method to translate spoken content from English to French might look like this:</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`Translate`</ph> method provides the following required parameters:</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Parameter</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Description</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Specifies the language of the incoming speech, from a list of supported language identifiers.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Specifies the language to translate the content into, from a list of supported language identifiers.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>A comma-separated set of features, which can include <ph id="ph1">`partial`</ph>, <ph id="ph2">`texttospeech`</ph>, and <ph id="ph3">`timinginfo`</ph>.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The locale-specific voice to use for final synthesis, from a list of supported voices.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`Translate`</ph> method also provides the following optional parameters to handle things like the audio-output format and profanity masking:</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Parameter</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Description</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Specifies the format of the text-to-speech audio stream returned by the service, either as <ph id="ph1">`audio/wav`</ph> or <ph id="ph2">`audio/mp3`</ph>.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Specifies how the service should handle profanity recognized in the speech.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Specifies how detected profanity is handled when the <ph id="ph1">`profanityaction`</ph> parameter is used.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Although an authorized WebSocket connection is created and opened, speech translation requires you to specify a target, or "to", language.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Because of its large number of supported (and growing) languages, the Speech Translation API provides a simple way to request lists of supported languages.</source>
        </trans-unit></group></body></file></xliff>