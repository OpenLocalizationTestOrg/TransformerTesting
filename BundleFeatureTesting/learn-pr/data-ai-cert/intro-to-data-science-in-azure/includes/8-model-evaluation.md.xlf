<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="8-model-evaluation.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">8-model-evaluation.2feb0f.b9be2ad3cfb96b037b6a7f7af5d68690e8b035c9.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">b9be2ad3cfb96b037b6a7f7af5d68690e8b035c9</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\intro-to-data-science-in-azure\includes\8-model-evaluation.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>This part of the process uses the results from the model to see how well it did in predicting the outcome, referred to as <bpt id="p1">*</bpt>Y<ept id="p1">*</ept>. Depending on how well your model performs, you might need to fine-tune some hyper-parameters within the model to improve results.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Tune the hyperparameters</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>Hyperparameters<ept id="p1">*</ept> are parameters used in model training that cannot be learned by the training process.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>These parameters must be set before model training begins.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Hyperparameters control how model training is done, which can have a significant impact on model accuracy.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>An example of a hyperparameter is the K parameter of the KNN model.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>This model defines regions of similar classes of items and determines which class a new item falls into by looking at the other items it has already classified.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Basically, KNN asks "what is this new item most similar too?".</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The K parameter tells the model how many other items to consider in making the determination.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>A K of 1 means only look at the single most similar item, and a K of 3 means look at the three most similar (closest) neighbors.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The value of K can have a significant impact on model accuracy.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Deep learning models use several hyperparameters.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>However, when there is a large amount of data, tuning hyperparameters can be a computationally heavy task for a machine.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>If the dataset isn't too large, a process called <bpt id="p1">*</bpt>grid searching<ept id="p1">*</ept> allows you to get more accurate results as to which hyperparameters are best for your data because it looks at many more cases for each parameter.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Another approach called the <bpt id="p1">*</bpt>random search method<ept id="p1">*</ept> searches randomly for the best hyperparameter values.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>This method is much less expensive computationally.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Since the dataset is only 10,000 rows, you move forward with grid searching.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Note that when using this method, two hyperparameters need to be defined: learning rate, and number of layers help identify the extent of  fine-tuning.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Hyperparameter tuning should be used with cross-validation so that the model is not overfitted to the training dataset.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Models can be configured to improve accuracy using hyperparameter tuning.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>This enables you to improve probabilistic outcomes, but at the cost of increased compute resources and time.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Don't worry if you don't understand this if you're not a data scientist.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The key takeaway is that models can be configured.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Evaluate the results</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This is the final step of the modeling process.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>However, since you'll usually have the modeling process repeat more than once, the first time this step runs is usually is not the end.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>When you evaluate the results you'll look at how accurate or inaccurate your predictions are.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Let's look at two different techniques for evaluating results: you can evaluate a classifier model, or assess a numerical prediction model.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Look for accuracy and precision</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>When evaluating a classification model a couple of metrics that are useful are accuracy and precision.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>To understand these terms, it's essential to understand what a confusion matrix is.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>A confusion matrix includes the following:</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>True positive<ept id="p1">**</ept>: the number of times a model predicts true (or yes) when it is actually yes</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>True negative<ept id="p1">**</ept>: the number of times a model predicts false (or no) when it is actually false</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>False negative<ept id="p1">**</ept>: the number of times a model predicts false when it is actually true</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>False positive<ept id="p1">**</ept>: the number of times a model predicts true when it is actually false</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>This data is formatted in a matrix format to understand how accurate the predictive model is:</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Predicted No</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Predicted Yes<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Actually No</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>True Negative</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>True Positive<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Actually Yes<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>False Negative<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>False Positive<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Accuracy<ept id="p1">**</ept> is the value of accurate predictions of yes and no over the total number of predictions.</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>You want this number to be as close to 1 as possible.</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>$${\dfrac{true\ positive + true\ negative}{true\ positive + true\ negative + false\ positive + false\ negative}}$$</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source>You want the result to be as close to <bpt id="p1">**</bpt>one<ept id="p1">**</ept> as possible.</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>Precision<ept id="p1">*</ept> is a measure of the consistency of the predictions.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source>This is represented by the following equation.</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source>$${\dfrac{true\ positive}{true\ positive + false\ positive}}$$</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source>As with accuracy, the precision of your model increases as the result moves closer to <bpt id="p1">**</bpt>one<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Evaluate the metrics with mean squared error</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Mean squared error (MSE) is one of the most popular model evaluation metrics in statistical modeling.</source>
        </trans-unit><trans-unit id="156" translate="yes" xml:space="preserve">
          <source>It allows you to look at how far your predictions are on average from the correct  values.</source>
        </trans-unit><trans-unit id="157" translate="yes" xml:space="preserve">
          <source>In the example with time series analysis, MSE is a valid approach to model evaluation.</source>
        </trans-unit><trans-unit id="158" translate="yes" xml:space="preserve">
          <source>The few metrics we have examined are just a subset of what is available for model evaluation.</source>
        </trans-unit><trans-unit id="159" translate="yes" xml:space="preserve">
          <source>The type of model will drive the direction of the model evaluation, but the technique you choose will depend on whether the model is a classification or numerical prediction.</source>
        </trans-unit></group></body></file></xliff>