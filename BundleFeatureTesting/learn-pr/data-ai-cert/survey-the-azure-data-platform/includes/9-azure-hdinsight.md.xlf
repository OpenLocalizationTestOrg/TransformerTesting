<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="9-azure-hdinsight.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9-azure-hdinsight.5cbf94.2836c36c760c0fa2205794e0136b1d63a3453f94.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2836c36c760c0fa2205794e0136b1d63a3453f94</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\survey-the-azure-data-platform\includes\9-azure-hdinsight.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Azure HDInsight provides technologies to help you ingest, process, and analyze big data.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>It supports batch processing, data warehousing, IoT, and data science.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Key features</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>HDInsight is a low-cost cloud solution.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>It includes Apache Hadoop, Spark, Kafka, HBase, Storm, and Interactive Query.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Hadoop<ept id="p1">**</ept> includes Apache Hive, HBase, Spark, and Kafka.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Hadoop stores data in a file system (HDFS).</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Spark stores data in memory.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>This difference in storage makes Spark about 100 times faster.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>HBase<ept id="p1">**</ept> is a NoSQL database built on Hadoop.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>It's commonly used for search engines.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>HBase offers automatic failover.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Storm<ept id="p1">**</ept> is a distributed real-time streamlining analytics solution.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Kafka<ept id="p1">**</ept> is an open-source platform that's used to compose data pipelines.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>It offers message queue functionality, which allows users to publish or subscribe to real-time data streams.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Ingesting data</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>As a data engineer, use Hive to run ETL operations on the data you're ingesting.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Or orchestrate Hive queries in Azure Data Factory.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Data processing</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>In Hadoop, use Java and Python to process big data.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Mapper consumes and analyzes input data.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>It then emits tuples that Reducer can analyze.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Reducer runs summary operations to create a smaller combined result set.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Spark processes streams by using Spark Streaming.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>For machine learning, use the 200 preloaded Anaconda libraries with Python.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Use GraphX for graph computations.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Developers can remotely submit and monitor jobs from Spark.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Storm supports common programming languages like Java, C#, and Python.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Queries</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>In Hadoop supports Pig and HiveQL languages.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>In Spark, data engineers use Spark SQL.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Data security</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Hadoop supports encryption, Secure Shell (SSH), shared access signatures, and Azure Active Directory security.</source>
        </trans-unit></group></body></file></xliff>