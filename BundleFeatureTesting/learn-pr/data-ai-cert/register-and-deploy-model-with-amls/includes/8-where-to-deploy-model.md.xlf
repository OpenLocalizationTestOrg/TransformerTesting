<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="8-where-to-deploy-model.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">8-where-to-deploy-model.cf84d7dbbbc2baba016a671dbd1e929a967a03ed.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">58a4551d054c19ac55d387910060f8858214e127</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\register-and-deploy-model-with-amls\includes\8-where-to-deploy-model.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Once a model has been trained and you are ready to make it available to your applications and services, you need to deploy it.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Deploying a model allows it to receive data from a client, process the data with the trained model, and return results back to the client.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>The Azure Machine Learning Service provides several places you can deploy your trained model using the Azure Machine Learning SDK, including:</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Location</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Type</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Description</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Azure Container Instances (ACI)<ept id="p1">](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where#aci)</ept></source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Testing</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>This is a single container instance managed by Azure Container Instances service.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>It has fast deployment speed (usually less than 5 minutes) and is an ideal environment for development and testing purpose.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Azure Kubernetes Service (AKS)<ept id="p1">](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where#aks)</ept></source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Real-time interface</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This is a set of containers managed by Azure Kubernetes Service.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>It provides high-scale production deployments, auto-scale, and a front end to handle ingress and egress requests.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>It usually takes around 20 minutes to set up, but this is a one-time setup and is ideal for production purpose deployment.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Azure Machine Learning Compute<ept id="p1">](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where#azuremlcompute)</ept></source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Batch interface</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Run batch prediction on serverless compute.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Supports normal and low-priority VMs created and managed by the Azure Machine Learning service.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Azure IoT Edge<ept id="p1">](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where#iotedge)</ept></source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>IoT module (Preview)</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>An Azure IoT Edge device is a Linux or Windows-based device that runs the Azure IoT Edge runtime.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Azure Machine Learning supports deploying machine learning models to IoT Edge devices as IoT Edge modules.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Once the model is deployed to IoT Edge devices, the model can be used in the edge device directly without connect to the cloud, which reduces the data transfer amount and reduces the response time.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Field-programmable gate array (FPGA)<ept id="p1">](https://docs.microsoft.com/azure/machine-learning/service/how-to-deploy-and-where#fpga)</ept></source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Web service (Preview)</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>FPGAs contain an array of programmable logic blocks, and a hierarchy of reconfigurable interconnects.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Compared to CPU and GPUs, FPGAs provide a combination of programmability and performance.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The hardware can be programmed so that it can provide model inference with hardware (which is usually much faster than software), and the hardware updates to a different set of models, which provides flexibility.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Azure Machine Learning supports deploying models to use FPGAs on Azure.</source>
        </trans-unit></group></body></file></xliff>