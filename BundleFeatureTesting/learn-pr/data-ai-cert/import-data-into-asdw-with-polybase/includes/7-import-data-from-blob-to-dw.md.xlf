<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="7-import-data-from-blob-to-dw.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7-import-data-from-blob-to-dw.218a490824c15c65ac119e4585c0712bd5d74e2b.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">49d010328dcc34a52d8d3c6b437a5e16990e59a5</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\import-data-into-asdw-with-polybase\includes\7-import-data-from-blob-to-dw.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>You can now import the data from the blob storage to the Azure SQL Data Warehouse database.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Let's connect to the database and run the appropriate SQL queries to create a staging table with the data.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>This exercise is optional.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>If you don't have an Azure account, or prefer not to do the exercise in your account, read the instructions to understand how to run PolyBase T-SQL commands to import data from an Azure Blob storage account into a SQL data warehouse.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Open the query editor in the Azure portal</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>You use a built-in query editor in the Azure portal to run the necessary queries.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>You can use any query tool that supports connecting to an Azure SQL Server instance.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Some common free tools you can use on Windows are Visual Studio and SQL Server Management Studio.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>On Linux and macOS, you can use Visual Studio Code with the mssql extension.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Sign in to the <bpt id="p1">[</bpt>Azure portal<ept id="p1">](https://portal.azure.com?azure-portal)</ept>.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>SQL database<ept id="p1">**</ept> in the left sidebar.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>If it's not present, use the search box at the top to search for the database by name.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Showing SQL databases</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>DemoDW<ept id="p1">**</ept> as the name of the target database where you want to import the data.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Query editor (preview)<ept id="p1">**</ept> from the <bpt id="p2">**</bpt>Common tools<ept id="p2">**</ept> section.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>This tool is a built-in SQL query editor.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Opening the query editor preview</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>If you want to work with a desktop-based tool, you can open Visual Studio from here.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Enter the admin or password credentials you used to create the database, and select <bpt id="p1">**</bpt>OK<ept id="p1">**</ept> to authenticate.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>The query explorer appears.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Query explorer in the Azure portal</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Create an import database</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>The first step in using PolyBase is to create a database-scoped credential that secures the credentials to the blob storage.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Create a master key first, and then use this key to encrypt the database-scoped credential named <bpt id="p1">**</bpt>AzureStorageCredential<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Paste the following code into the query window.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Replace the <ph id="ph1">`SECRET`</ph> value with the access key you retrieved in the previous exercise.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>It should report <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph></source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Create an external data source connection</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Use the database-scoped credential to create an external data source named <bpt id="p1">**</bpt>AzureStorage<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Note the location URL point to the container named <bpt id="p1">**</bpt>data-files<ept id="p1">**</ept> that you created in the blob storage.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>The type <bpt id="p1">**</bpt>Hadoop<ept id="p1">**</ept> is used for both Hadoop-based and Azure Blob storage-based access.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Paste the following code into the query window.</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Replace the <ph id="ph1">`LOCATION`</ph> value with your correct value from the previous exercise.</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>It reports <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph>.</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Define the import file format</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Define the external file format named <bpt id="p1">**</bpt>TextFile<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>This name indicates to PolyBase that the format of the text file is <bpt id="p1">**</bpt>DelimitedText<ept id="p1">**</ept> and the field terminator is a comma.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Paste the following code into the query window:</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>It reports <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph>.</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Create a temporary table</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Create an external table named <ph id="ph1">`dbo.temp`</ph> with the column definition for your table.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>At the bottom of the query, use a <ph id="ph1">`WITH`</ph> clause to call the data source definition named <bpt id="p1">**</bpt>AzureStorage<ept id="p1">**</ept>, as previously defined, and the file format named <bpt id="p2">**</bpt>TextFile<ept id="p2">**</ept>, as previously defined.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The location denotes that the files for the load are in the root folder of the data source.</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>External tables are in-memory tables that don't persist onto the physical disk.</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>External tables can be queried like any other table.</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source>The table definition must match the fields defined in the input file.</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source>There are 12 defined columns, with data types that match the input file data.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Add the following code into the Visual Studio window underneath the previous code:</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source>It takes a few seconds to complete and reports <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph>.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source>Create a destination table</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Create a physical table in the SQL Data Warehouse database.</source>
        </trans-unit><trans-unit id="156" translate="yes" xml:space="preserve">
          <source>In the following example, you create a table named <ph id="ph1">`dbo.StageDate`</ph>.</source>
        </trans-unit><trans-unit id="157" translate="yes" xml:space="preserve">
          <source>The table has a clustered column store index defined on all the columns.</source>
        </trans-unit><trans-unit id="158" translate="yes" xml:space="preserve">
          <source>It uses a table geometry of <ph id="ph1">`round_robin`</ph> by design because <ph id="ph2">`round_robin`</ph> is the best table geometry to use for loading data.</source>
        </trans-unit><trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Paste the following code into the query window:</source>
        </trans-unit><trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="161" translate="yes" xml:space="preserve">
          <source>It takes a few seconds to complete and reports <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph>.</source>
        </trans-unit><trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Add statistics onto columns to improve query performance</source>
        </trans-unit><trans-unit id="163" translate="yes" xml:space="preserve">
          <source>As an optional step, create statistics on columns that feature in queries to improve the query performance against the table.</source>
        </trans-unit><trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Paste the following code into the query window:</source>
        </trans-unit><trans-unit id="165" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Run<ept id="p1">**</ept> to run the query.</source>
        </trans-unit><trans-unit id="166" translate="yes" xml:space="preserve">
          <source>It reports <ph id="ph1">`Query succeeded: Affected rows: 0.`</ph>.</source>
        </trans-unit><trans-unit id="167" translate="yes" xml:space="preserve">
          <source>You've loaded your first staging table in Azure SQL Data Warehouse.</source>
        </trans-unit><trans-unit id="168" translate="yes" xml:space="preserve">
          <source>From here, you can write further Transact-SQL queries to perform transformations into dimension and fact tables.</source>
        </trans-unit><trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Try it out by querying the <ph id="ph1">`StageDate`</ph> table in the query explorer or in another query tool.</source>
        </trans-unit><trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Refresh the view on the left to see the new table or tables that you created.</source>
        </trans-unit><trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Reuse the previous steps in a persistent SQL script to load additional data, as necessary.</source>
        </trans-unit></group></body></file></xliff>