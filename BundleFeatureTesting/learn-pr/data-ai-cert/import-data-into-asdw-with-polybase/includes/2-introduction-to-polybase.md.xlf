<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="2-introduction-to-polybase.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2-introduction-to-polybase.e2a524a1e3337e33e14039413720099be479442c.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">e042b4e07887898ca144862e1b28ee086e0df798</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\import-data-into-asdw-with-polybase\includes\2-introduction-to-polybase.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Azure SQL Data Warehouse is a relational big data store that uses a massively parallel processing (MPP) architecture.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>It takes advantage of the on-demand elastic scale of Azure compute and storage resources to load and process petabytes of data.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>With SQL Data Warehouse, you get quicker access to the critical information you need to make good business decisions.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>There are two versions of compute nodes that are available at the time of writing.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Both SQL Data Warehouse Generation 1 (Gen1) and Generation 2 (Gen2) can have 60 compute nodes assigned to process data when the maximum Data Warehouse Unit (DWU) is selected.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Gen2 is a newer architecture that has five times the compute capacity and four times the concurrent queries of Gen1.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>A key feature of Azure SQL Data Warehouse is that you pay for only the processing you need.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>You can decide how much parallelism is needed for your work.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>You also can pause the compute nodes when it's not in use.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>In this way, you pay for only the CPU time you use.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Azure SQL Data Warehouse supports many loading methods.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>These methods include non-PolyBase options such as BCP and the SQL Bulk Copy API.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The fastest and most scalable way to load data is through PolyBase.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>PolyBase is a technology that accesses external data stored in Azure Blob storage, Hadoop, or Azure Data Lake Store via the Transact-SQL language.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The following architecture diagram shows how loading is achieved with each HDFS bridge of the data movement service (DMS) on every compute node that connects to an external resource such as Azure Blob storage.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>PolyBase then bidirectionally transfers data between SQL Data Warehouse and the external resource to provide the fast load performance.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Loading Azure SQL Data Warehouse via PolyBase</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Use PolyBase to extract, load, and transform data</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Follow these steps to implement a PolyBase extract, load, and transform process for SQL Data Warehouse:</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Extract the source data into text files.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Load the data into Azure Blob storage, Hadoop, or Azure Data Lake Store.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Import the data into SQL Data Warehouse staging tables by using PolyBase.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Transform the data (optional).</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Insert the data into production tables.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Let's look more closely at the import process defined by steps 1-3.</source>
        </trans-unit></group></body></file></xliff>