<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="8-summary.yml" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">8-summary.d82ef469b275a53669e4e69e5656ba1cd383bd05.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">018dca3a342507fb982af9613dc6bddaa8226882</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\import-data-into-asdw-with-polybase\8-summary.yml</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Summary</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Summary</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Summary</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Check your knowledge</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Mike is the data engineer for Contoso and has a data warehouse created with a database named Crystal.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Within the database is a table named DimSuppliers.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>The suppliers' information is stored in a single text file named Suppliers.txt and is 1,200 MB in size.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>It's currently stored in a container with an Azure blob store.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Your Azure SQL Data Warehouse is configured as Gen 2 DW30000c.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>How can Mike maximize the performance of the data load?</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Increase the Gen 2 DWU units.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's not the correct answer.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Gen 2 DW30000c is the highest limit and can't be scaled beyond this size.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Split the text file into 60 files of 20 MB each.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's the correct answer.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Separating the single text file of Suppliers.txt into 60 files can take advantage of the fact that Gen 2 DW30000c uses 60 compute nodes and the parallelism of the data load can be evenly spread for quicker performance.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Use Gen 1 DW6000.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's not the correct answer.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Gen 1 compute nodes have less power than Gen 2 compute nodes and won't improve the performance.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Mike is the data engineer for Contoso and has a data warehouse created with a database named Crystal.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Mike created a master key, followed by a database-scoped credential.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>What should he create next?</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>An external table.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's not the correct answer.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Mike must have an external data source before he creates an external table.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>An external data source.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's the correct answer.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>After the master key and the database-scoped credential are created, Mike should create an external data source that contains a URL to the blob location and the name of the database-scoped credential.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>A physical table.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>That's not the correct answer.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve" uid="learn.data-ai.import-data-into-asdw-with-polybase.summary">
          <source>Mike must have an external data source and an external table before he can create a physical table.</source>
        </trans-unit></group></body></file></xliff>