<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="5-stages-for-processing-big-data.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5-stages-for-processing-big-data.4977d0.8a493f8ebcad685fa33388ea2f411f87e8038832.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">8a493f8ebcad685fa33388ea2f411f87e8038832</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\introduction-to-azure-data-lake-storage\includes\5-stages-for-processing-big-data.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Azure Data Lake Storage Gen2 plays a fundamental role in a wide range of big data architectures.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>These architectures can involve the creation of:</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>A modern data warehouse.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Advanced analytics against big data.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>A real-time analytical solution.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>There are four stages for processing big data solutions that are common to all architectures:</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Ingestion<ept id="p1">**</ept> - The ingestion phase identifies the technology and processes that are used to acquire the source data.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This data can come from files, logs, and other types of unstructured data that must be put into the Data Lake Store.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The technology that is used will vary depending on the frequency that the data is transferred.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>For example, for batch movement of data, Azure Data Factory may be the most appropriate technology to use.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>For real-time ingestion of data, Apache Kafka for HDInsight or Stream Analytics may be an appropriate technology to use.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Store<ept id="p1">**</ept> - The store phase identifies where the ingested data should be placed.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>In this case, we're using Azure Data Lake Storage Gen2.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Prep and train<ept id="p1">**</ept> - The prep and train phase identifies the technologies that are used to perform data preparation and model training and scoring for data science solutions.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The common technologies that are used in this phase are Azure Databricks or Azure HDInsight Machine Learning Services.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Model and serve<ept id="p1">**</ept> - Finally, the model and serve phase involves the technologies that will present the data to users.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>These can include visualization tools such as Power BI, or other data stores such as Azure SQL Data Warehouse, Azure Cosmos DB, Azure SQL Database, or Azure Analysis Services.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Often, a combination of these technologies will be used depending on the business requirements.</source>
        </trans-unit></group></body></file></xliff>