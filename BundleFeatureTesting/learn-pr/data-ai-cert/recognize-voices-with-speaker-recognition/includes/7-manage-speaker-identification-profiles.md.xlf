<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="7-manage-speaker-identification-profiles.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7-manage-speaker-identification-profiles.a0d4cb3d183f96b430df9b69350722bdf41a2455.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">8ebc55eed126cb8d5073a236d1c6fdea36565b9d</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\recognize-voices-with-speaker-recognition\includes\7-manage-speaker-identification-profiles.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Creating identification profiles is a straightforward process that uses the identification-management methods in the Speaker Identification API.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Use the Speaker Identification API to manage identification profiles</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Like speaker-verification profiles, you manage speaker-identification profiles with the Speaker Identification API by:</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Sending an authorized web request to the subscription endpoint.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Observing the information returned from the call.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The primary methods you use to create and manage identification profiles are the <ph id="ph1">`Create Profile`</ph> and <ph id="ph2">`Create Enrollment`</ph> methods in the Speaker Identification API.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>As with speaker verification, the <ph id="ph1">`Create Profile`</ph> method accepts a region or locale parameter for creating a profile based on a specific locale, and it returns a unique identifier for the profile.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>But the <ph id="ph1">`Create Enrollment`</ph> method is where the significant work happens.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`Create Enrollment`</ph> method accepts an audio file (as a binary file payload) that <bpt id="p1">*</bpt>must<ept id="p1">*</ept> meet the same criteria as the files used for speaker verification:</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Property</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Required value</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Container<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>WAV</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Encoding<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>PCM</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Rate<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>16K</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Sample format<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>16-bit</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Channels<ept id="p1">**</ept></source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Mono</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`Create Enrollment`</ph> method requires a single parameter to be passed to the service.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>This <ph id="ph1">`identificationProfileId`</ph> parameter, which is returned by the <ph id="ph2">`Create Profile`</ph> method, identifies which profile to apply the enrollment submission to.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>You can also pass an optional <ph id="ph1">`shortAudio`</ph> parameter to instruct the service to bypass audio-length requirements.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This parameter is a "yes" or "no" (Boolean) value that tells the service to waive the recommended minimum audio limit needed for enrollment.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>A parameter passed to the Speaker Identification API <ph id="ph1">`Create Enrollment`</ph> method is typically sent in the query string as part of the endpoint URL.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>This example includes the optional <ph id="ph1">`shortAudio`</ph> parameter:</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>When you're enrolling a speaker for identification without using the <ph id="ph1">`shortAudio`</ph> parameter, the audio files must be at least 5 seconds long and no longer than 5 minutes.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">*</bpt>minimum<ept id="p1">*</ept> recommended amount of accumulated speech for enrollment, after removing silence, is 30 seconds.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>After accumulating 30 seconds of speech, the profileâ€™s enrollment status is changed from <ph id="ph1">`enrolling`</ph> to <ph id="ph2">`enrolled`</ph> to indicate that it's ready to be used for identification.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>When you're using the <ph id="ph1">`shortAudio`</ph> parameter, audio files can be as short as 1 second long, but the accuracy of speaker identification is potentially less reliable.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Send an audio payload</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>To send an audio payload to the Speaker Identification <ph id="ph1">`Create Enrollment`</ph> method, you must include a binary file, such as a stream or byte array, in the web request, and then send the request via a standard HTTP POST method.</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Binary file payload</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>You create and send a binary file payload to the <ph id="ph1">`Create Enrollment`</ph> method by using standard, language-specific methods for creating and sending binary content.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>For example, in C#, a binary payload could come from an audio file (containing a voice recording of the person speaking) located on a local computer:</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>In the prior example, the optional <ph id="ph1">`shortAudio`</ph> parameter tells the method to waive the recommended minimum audio limit needed for enrollment and to allow audio files as little as 1 second long.</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Return values</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>If you have long audio files, creating speaker-identification enrollments can take a while.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Because enrollment is potentially a long-running process, the <ph id="ph1">`Create Enrollment`</ph> method is an operation location and result method.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>To get the status of an enrollment operation, you need to:</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Send an initial request, with the specified payload.</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Get the <bpt id="p1">**</bpt>operation location<ept id="p1">**</ept> value from the initial request.</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Poll the <bpt id="p1">**</bpt>operation location<ept id="p1">**</ept> value that's returned, until the <bpt id="p2">**</bpt>operation result<ept id="p2">**</ept> value indicates that the operation is successful.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>Call the <ph id="ph1">`Get Profile`</ph> method in the Speaker Identification API.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source>When the enrollment process is successful, the results returned from the <ph id="ph1">`Get Profile`</ph> method are in a well-formatted JSON object or array that looks like this example:</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>With a speaker verification or identification profile in place, you can now use Azure Cognitive Services to recognize that speaker.</source>
        </trans-unit></group></body></file></xliff>