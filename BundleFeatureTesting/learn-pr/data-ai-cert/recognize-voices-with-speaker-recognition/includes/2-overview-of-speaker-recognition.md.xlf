<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="2-overview-of-speaker-recognition.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2-overview-of-speaker-recognition.f40e099b27e395604fba43acb5c2e826d8fb8549.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">0c22dfe9e983106cd6fd7567495a39d16386a819</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\data-ai-cert\recognize-voices-with-speaker-recognition\includes\2-overview-of-speaker-recognition.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The Speaker Recognition APIs in Azure Cognitive Services use machine learning and artificial intelligence to provide robust services that:</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Identify individual speakers.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Use speech for authentication.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>You can use any programming language or operating system to integrate these services into your apps and services.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Azure Cognitive Services speaker recognition</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Speaker recognition is divided into two categories:</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Speaker verification:<ept id="p1">**</ept> Automatically verify and authenticate users by using their voice or speech.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Speaker identification:<ept id="p1">**</ept> Automatically identify the person who's speaking in an audio file by comparing the voice to a group of prospective speakers.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The Speaker Recognition APIs</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>All life forms seem to have built-in, biologically adapted methods of communication.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Whether you're a blue whale, a bumblebee, a cicada, or a human, your individual "voice" is unique.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Our planet is filled with over 7.5 billion human voices, each one unique and distinct from the others.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Through simple REST-based service calls, the Speaker Recognition APIs provide algorithms that allow you to:</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Verify and identify human voices.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Organize voices into manageable profiles.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Verification and identification</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>The methods provided by the Speaker Recognition APIs fall into three categories:</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Verification:<ept id="p1">**</ept> Checking the likelihood that two voices belong to the same person.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Identification and recognition:<ept id="p1">**</ept> Determining whether a voice matches another known voice.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Enrollment:<ept id="p1">**</ept> Registering voices to be verified or identified.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The Speaker Recognition APIs allow you to use the power of artificial intelligence to:</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Authenticate users before allowing them to access apps and services.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Identify speakers in video streams.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Identify speakers in real-time chat scenarios.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Improve security for sensitive resources.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Replace cumbersome legacy authentication.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Speaker recognition is often referred to as "voice recognition."</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Speaker recognition is the process of identifying a person based on characteristics of that person's voice.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>There's a difference between <bpt id="p1">_</bpt>speaker recognition<ept id="p1">_</ept> and <bpt id="p2">_</bpt>speech recognition<ept id="p2">_</ept>.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Speech recognition attempts to determine the <bpt id="p1">_</bpt>content of spoken words<ept id="p1">_</ept>, and speaker recognition attempts to identify the <bpt id="p2">_</bpt>speaker of the content<ept id="p2">_</ept>.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Great acoustics</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Speaker recognition evaluates the vital acoustic features of speech that differ between individuals.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>These acoustic patterns are determined by things like the size and shape of someone's throat and mouth.</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Everyone also has certain speech patterns, such as speaking style and voice pitch.</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Great acoustics</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Scientific progress in the field of speaker verification has resulted in speaker recognition now being classified as a "behavioral biometric."</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Just like the difference between speech recognition and speaker recognition, the acts of speaker <bpt id="p1">*</bpt>verification<ept id="p1">*</ept> and speaker <bpt id="p2">*</bpt>identification<ept id="p2">*</ept> also differ:</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Speaker verification:<ept id="p1">**</ept> An attempt to determine if a speaker has a <bpt id="p2">*</bpt>certain "claimed" identity<ept id="p2">*</ept>.</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Speaker identification:<ept id="p1">**</ept> An attempt to determine an <bpt id="p2">*</bpt>unknown speaker's identity<ept id="p2">*</ept>.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>In both cases, existing voices or voice samples must be available for comparison.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The process of creating voice samples is referred to as <bpt id="p1">*</bpt>enrollment<ept id="p1">*</ept>.</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Enrollment</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In speaker recognition, enrollment is the process of prerecording a speaker's voice to extract the acoustic and speech patterns that form a <bpt id="p1">_</bpt>voice print<ept id="p1">_</ept>.</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>A voice print is often referred to as a <bpt id="p1">*</bpt>voice template<ept id="p1">*</ept> or <bpt id="p2">*</bpt>voice model<ept id="p2">*</ept>.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>In typical speaker-verification scenarios, sample speech "utterances" are prerecorded to use later when comparing voice prints.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The process of speaker <bpt id="p1">*</bpt>identification<ept id="p1">*</ept> is more difficult because many times an utterance is newly introduced to the system.</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>For example, a speaker-recognition system could be trained to identify a famous US president from samples of inauguration speeches.</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>But identifying a president from new content, such as a State of the Union speech, requires comparison of the spoken content against multiple voice prints to determine the best match.</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Identifying US presidents through speaker identification</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Because the algorithms behind verification and identification are different, the enrollment processes for these services are also separate.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source>Behind the scenes, two types of speaker-recognition systems are in effect: <bpt id="p1">*</bpt>text-dependent<ept id="p1">*</ept> and <bpt id="p2">*</bpt>text-independent<ept id="p2">*</ept>.</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Text-dependent:<ept id="p1">**</ept> Used for enrollment for speaker verification, where prompts are known and common across all speakers.</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Text-independent:<ept id="p1">**</ept> Used for enrollment for speaker identification, where there's no (needed) cooperation by the speaker.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source>For text-independent scenarios, enrollment often happens without a user's knowledge, because speaker-identification systems don't need to compare what was said at enrollment.</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>The text-dependent system, which is the most controlled of these systems, is at the core of speaker verification.</source>
        </trans-unit></group></body></file></xliff>