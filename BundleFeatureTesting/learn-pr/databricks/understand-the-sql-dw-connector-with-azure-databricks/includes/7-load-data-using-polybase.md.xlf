<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="7-load-data-using-polybase.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7-load-data-using-polybase.2db3070cb07cb125bb4491795de5f8be8698b7f4.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">eb042325f310724f09f60a015f998b3032faee36</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\understand-the-sql-dw-connector-with-azure-databricks\includes\7-load-data-using-polybase.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>PolyBase is a technology that accesses data outside of a database via the T-SQL language.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>In Azure SQL Data Warehouse, you can import and export data to and from Azure Blob storage and Azure Data Lake Store.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>In this unit, you'll learn how to load data from Azure Blob storage into SQL Data Warehouse by using PolyBase.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Make a connection to SQL Data Warehouse</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Open Azure Data Studio.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Go to the <bpt id="p1">**</bpt>Servers<ept id="p1">**</ept> list in the menu on the left side of Azure Data Studio.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Right-click the connection that you made to the SQL Data Warehouse database and select <bpt id="p1">**</bpt>New Query<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Right-click the SQL Data Warehouse connection and select New Query</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Create an external data source</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Run the following statements in the query window to create an external data source.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The statements define connection details to the labdata container of the Azure storage account that you set up in your resource group.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Replace the token <ph id="ph1">`&lt;Name_Of_Storage_Account&gt;`</ph> with the name of the Azure storage account that you set up in your resource group in the final section of the "Set up the environment" unit.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>External data source query</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>TYPE = <ph id="ph1">`[ HADOOP | SHARD_MAP_MANAGER | RDBMS | BLOB_STORAGE ]`</ph></source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Specifies the data source type.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Use <ph id="ph1">`HADOOP`</ph> when the external data source is Hadoop or Azure Blob storage  for Hadoop.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>LOCATION = <ph id="ph1">`&lt;location_path&gt;`</ph></source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>For Azure Blob storage with Hadoop, specifies the URI for connecting to Azure Blob storage.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>LOCATION = <ph id="ph1">`wasb[s]://container@account_name.blob.core.windows.net`</ph></source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Define the external file format</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>A definition of the external file format helps SQL Data Warehouse parse the format of the external file to be loaded.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>It defines the field terminator, string delimiter, and date field format.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>These properties help with capturing the fields in a file.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Clear the query window and execute these statements to define the external file format:</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>FIELD_TERMINATOR = <ph id="ph1">`field_terminator`</ph>.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Applies only to delimited text files.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>This property specifies one or more characters that mark the end of each field (column) in the text-delimited file.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The external file used for this exercise uses the comma (,) as the text delimiter.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>STRING_DELIMITER = <ph id="ph1">`string_delimiter`</ph>.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Specifies the field terminator for data of type string in the text-delimited file.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>DATE_FORMAT = <ph id="ph1">`datetime_format`</ph>.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Specifies a custom format for all date and time data that appears in a delimited text file.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>The TransactionDate field holds date values (for example, "2017-01-24 00:00:00.000").</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Create a schema for the external table</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Clear the query window and run this statement to create a schema for the external table:</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>Create the external table</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>External tables refer to data from an external data source.</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Data isn't stored in SQL Data Warehouse.</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Clear the query window and run these statements to define an external table:</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`CREATE EXTERNAL TABLE`</ph> allows one or more column definitions.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>The column definitions, including the data types and number of columns, need to match the data in the external files.</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>If there's a mismatch, the file rows will be rejected when the data is queried.</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>LOCATION = <ph id="ph1">`folder_or_filepath`</ph>.</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Specifies the folder or the file path and file name for the data in Hadoop or Azure Blob storage.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>The location starts at the <bpt id="p1">*</bpt>root folder<ept id="p1">*</ept>.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source>The root folder is the data location specified in the external data source.</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>In the previous statement, the <ph id="ph1">`Transaction.txt`</ph> file contains the data.</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>This file is in the container specified in the external data source.</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source>DATA_SOURCE = <ph id="ph1">`external_data_source_name`</ph>.</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source>Specifies the name of the external data source that contains the location of the external data.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source>This location is either Hadoop or Azure Blob storage.</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Here we're referring to the <ph id="ph1">`LabAzureStorage`</ph> external data store that you defined earlier.</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source>This external data store points to the container in the Azure Blob storage account.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source>FILE_FORMAT = <ph id="ph1">`external_file_format_name`</ph>.</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Specifies the name of the external file format object that stores the file type and compression method for the external data.</source>
        </trans-unit><trans-unit id="156" translate="yes" xml:space="preserve">
          <source>In the previous statement, <ph id="ph1">`FILE_FORMAT`</ph> is set to the <ph id="ph2">`TextFileFormat`</ph> object that you created earlier.</source>
        </trans-unit><trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p1">_</bpt>Reject options<ept id="p1">_</ept>.</source>
        </trans-unit><trans-unit id="158" translate="yes" xml:space="preserve">
          <source>You can specify reject parameters that determine how PolyBase will handle dirty records it retrieves from the external data source.</source>
        </trans-unit><trans-unit id="159" translate="yes" xml:space="preserve">
          <source>A data record is considered <bpt id="p1">*</bpt>dirty<ept id="p1">*</ept> if its data types or the number of columns don't match the column definitions of the external table.</source>
        </trans-unit><trans-unit id="160" translate="yes" xml:space="preserve">
          <source>REJECT_TYPE = <ph id="ph1">`value | percentage`</ph>.</source>
        </trans-unit><trans-unit id="161" translate="yes" xml:space="preserve">
          <source>Specifies whether the <ph id="ph1">`REJECT_VALUE`</ph> option is specified as a literal value or a percentage.</source>
        </trans-unit><trans-unit id="162" translate="yes" xml:space="preserve">
          <source>REJECT_VALUE.</source>
        </trans-unit><trans-unit id="163" translate="yes" xml:space="preserve">
          <source>If <ph id="ph1">`REJECT_TYPE`</ph> is <ph id="ph2">`value`</ph>, the PolyBase query will fail when the number of rejected rows exceeds <ph id="ph3">`REJECT_VALUE`</ph>.</source>
        </trans-unit><trans-unit id="164" translate="yes" xml:space="preserve">
          <source>If <ph id="ph1">`REJECT_TYPE`</ph> is <ph id="ph2">`percentage`</ph>, the PolyBase query will fail when the percentage of failed rows exceeds <ph id="ph3">`REJECT_VALUE`</ph>.</source>
        </trans-unit><trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The percentage of failed rows is calculated at intervals.</source>
        </trans-unit><trans-unit id="166" translate="yes" xml:space="preserve">
          <source>In the above statement, <ph id="ph1">`REJECT_VALUE`</ph> is set to <ph id="ph2">`1`</ph> to avoid headers in the external text file.</source>
        </trans-unit><trans-unit id="167" translate="yes" xml:space="preserve">
          <source>Clear the query window and run this statement to get data from the external table:</source>
        </trans-unit><trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Create a schema for the table</source>
        </trans-unit><trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Clear the query window and run this statement to create a schema for tables:</source>
        </trans-unit><trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Create a SQL Data Warehouse table and load data</source>
        </trans-unit><trans-unit id="171" translate="yes" xml:space="preserve">
          <source>Create a table in SQL Data Warehouse by using the CREATE TABLE AS SELECT (CTAS) statement.</source>
        </trans-unit><trans-unit id="172" translate="yes" xml:space="preserve">
          <source>It's a fully parallelized operation that creates a new table based on the output of a SELECT statement.</source>
        </trans-unit><trans-unit id="173" translate="yes" xml:space="preserve">
          <source>In this exercise, the CTAS statement is used to create a table in SQL Data Warehouse that's based on the external table that you defined earlier.</source>
        </trans-unit><trans-unit id="174" translate="yes" xml:space="preserve">
          <source>CTAS doesn't just create tables.</source>
        </trans-unit><trans-unit id="175" translate="yes" xml:space="preserve">
          <source>It also loads data obtained via the SELECT statement.</source>
        </trans-unit><trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Clear the query window and run this statement to create a table in SQL Data Warehouse:</source>
        </trans-unit><trans-unit id="177" translate="yes" xml:space="preserve">
          <source>DISTRIBUTION = <ph id="ph1">`[ HASH ( distribution_column_name ) | ROUND_ROBIN | REPLICATE ]`</ph>.</source>
        </trans-unit><trans-unit id="178" translate="yes" xml:space="preserve">
          <source>The CTAS statement requires a distribution option.</source>
        </trans-unit><trans-unit id="179" translate="yes" xml:space="preserve">
          <source>This option doesn't have a default value.</source>
        </trans-unit><trans-unit id="180" translate="yes" xml:space="preserve">
          <source>The table in this example is created by using the <ph id="ph1">`HASH`</ph> distribution method on the <ph id="ph2">`TransactionId`</ph> column.</source>
        </trans-unit><trans-unit id="181" translate="yes" xml:space="preserve">
          <source>LABEL.</source>
        </trans-unit><trans-unit id="182" translate="yes" xml:space="preserve">
          <source>This option labels the query, which makes it easy to identify.</source>
        </trans-unit></group></body></file></xliff>