<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="4-complete-labs-in-azure-databricks.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4-complete-labs-in-azure-databricks.1f3616820d19d17b5344d0ca5116251b422d4dce.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5416133a9991942f18df53b29f8962872485606c</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\streaming-in-azure-databricks\includes\4-complete-labs-in-azure-databricks.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Now it's time to perform some analytics on a sample data set by using Spark Structured Streaming and the Azure event hub that you created.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>To complete the following procedures, you must already have deployed your Azure Databricks workspace in the Azure portal.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Clone the Databricks archive</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>From the Azure portal, go to your deployed Azure Databricks workspace and select <bpt id="p1">**</bpt>Launch Workspace<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>In the Workspace, by using the command bar on the left, select <bpt id="p1">**</bpt>Workspace<ept id="p1">**</ept><ph id="ph1"> &gt; </ph><bpt id="p2">**</bpt>Users<ept id="p2">**</ept> &gt; your username (the entry with the house icon).</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In the blade that appears, select the downward-pointing chevron next to your name, and select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Import Notebooks<ept id="p1">**</ept> dialog box, select <bpt id="p2">**</bpt>URL<ept id="p2">**</ept> and paste in the following URL:</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>A folder named after the archive should appear.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Select it.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The folder will contain one or more notebooks that you'll use in completing this lab.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Complete four notebooks</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Complete the following notebooks in the 08-Streaming folder:</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>01-Getting started<ept id="p1">**</ept>:  This notebook gets you started with your event hub.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>If you already created your event hub in the previous unit, you can skip this notebook.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>02-Spark-Structured-Streaming<ept id="p1">**</ept>: In this notebook, you work on a sample dataset to perform some batch and interactive processing.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>You'll also create streaming queries to update the destination dataset.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>03-Event-Hubs<ept id="p1">**</ept>: This notebook gives detailed instructions on how to perform processing of messages in near real time through Spark Structured Streaming, by sending a batch of messages to Event Hubs.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>04-Streaming-with-Databricks-Delta<ept id="p1">**</ept>: In this notebook, you finally write your streaming data to Azure Data Lake storage.</source>
        </trans-unit></group></body></file></xliff>