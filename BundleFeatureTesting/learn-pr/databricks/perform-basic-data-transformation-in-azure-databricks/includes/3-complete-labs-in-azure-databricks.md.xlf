<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="3-complete-labs-in-azure-databricks.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3-complete-labs-in-azure-databricks.cc5cb5.75002a05ce658185b13d1813e16920c2f5f9736f.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">75002a05ce658185b13d1813e16920c2f5f9736f</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\perform-basic-data-transformation-in-azure-databricks\includes\3-complete-labs-in-azure-databricks.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Now it's time to switch to the Databricks workspace and get hands-on with some basic transformation techniques.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>To complete the following procedures, you must have already deployed your Azure Databricks workspace in your Azure portal.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Clone the Databricks archive</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>From the Azure portal, go to your Databricks workspace and select <bpt id="p1">**</bpt>Launch workspace<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>In the left pane, select <bpt id="p1">**</bpt>Workspace<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Users<ept id="p2">**</ept>, and then select your username (the entry with the house icon).</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In the pane that appears, select the downward-pointing chevron next to your name, and then select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Import Notebooks<ept id="p1">**</ept> pane, select <bpt id="p2">**</bpt>URL<ept id="p2">**</ept>, and paste in the following URL:</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>A folder named after the archive should appear.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Select that <bpt id="p1">*</bpt>05.1-Basic-ETL<ept id="p1">*</ept> folder.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>The folder contains one or more notebooks that you'll use in completing this lab.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Complete the following notebooks</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>To complete the labs, continue working within your Azure Databricks workspace and open the new <bpt id="p1">*</bpt>05.1-Basic-ETL<ept id="p1">*</ept> folder.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Within the folder, you'll find <bpt id="p1">_</bpt>Python<ept id="p1">_</ept>, <bpt id="p2">_</bpt>Scala<ept id="p2">_</ept>, and <bpt id="p3">_</bpt>Spark<ept id="p3">_</ept> subfolders.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Choose the folder for the language you prefer to use, open the corresponding folder, and then open the notebook.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Follow the instructions within the notebook until you've completed the entire notebook.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Then continue with the remaining notebooks in order:</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>01-Course-Overview-and-Setup<ept id="p1">**</ept>: This notebook gets you started with your Databricks workspace.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>02-ETL-Process-Overview<ept id="p1">**</ept>: This notebook contains exercises to help you query large data files and visualize your results.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>03-Connecting-to-Azure-Blob-Storage<ept id="p1">**</ept>: You do basic data aggregation and joins in this notebook.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>04-Connecting-to-JDBC<ept id="p1">**</ept>: This notebook lists the steps for accessing data from various sources by using Databricks.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>05-Applying-Schemas-to-JSON<ept id="p1">**</ept>: In this notebook, you learn how to query JSON and hierarchical data with DataFrames.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>06-Corrupt-Record-Handling<ept id="p1">**</ept>: This notebook lists exercises that help you create an Azure Data Lake Storage Gen2 storage account and use Databricks DataFrames to query and analyze this data.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>07-Loading-Data-and-Productionalizing<ept id="p1">**</ept>: Here you use Databricks to query and analyze data stores in Azure Data Lake Storage Gen2.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Parsing-Nested-Data<ept id="p1">**</ept>: This notebook is in the <bpt id="p2">*</bpt>Optional<ept id="p2">*</ept> subfolder.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>It includes a sample project you can explore later.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>You'll find corresponding notebooks within the <bpt id="p1">*</bpt>Solutions<ept id="p1">*</ept> subfolder.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>These notebooks contain finished cells for exercises that ask you to complete one or more challenges.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Refer to these if you get stuck or simply want to see the solution.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>After you've completed the notebooks, return to this screen, and continue to the next step.</source>
        </trans-unit></group></body></file></xliff>