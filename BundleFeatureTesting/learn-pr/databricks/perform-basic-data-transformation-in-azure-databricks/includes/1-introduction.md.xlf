<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="1-introduction.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1-introduction.15a796.edde7f554b3a370789eaf6ec6f6a33ebbbb6c268.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">edde7f554b3a370789eaf6ec6f6a33ebbbb6c268</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\perform-basic-data-transformation-in-azure-databricks\includes\1-introduction.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Azure Databricks uses DataFrames to query, process, and analyze large volumes of data.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>The core structure of the data in a DataFrame is immutable.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Being immutable means that the data structure can't be changed after it's created.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>So how do you use Databricks if you need to change the structure of the original data?</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>You can change the format for the original data through <bpt id="p1">*</bpt>data transformation<ept id="p1">*</ept>.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Data transformation is one of the most important aspects of the data-warehousing process.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>When you receive data in different unstructured formats, you need to integrate the data into a common format before warehousing it.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This transformation makes your data easy to use for any further analysis.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Based on the complexity of the raw data and your final output requirements, there are different transformation techniques you can use.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>For example, you might apply schemas to semistructured or tabular raw data.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>You might also use built-in functions to clean up corrupt data.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Databricks supports the end-to-end process of extracting data from the source, transforming that data, and finally loading the data into the target database.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This entire process is known as extract, transform, and load (ETL).</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Learning objectives</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>In this module, you'll:</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Transform data in Azure Databricks by applying schemas to JSON data.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Handle corrupt records.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>Load data and put it into production.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Apply standard and custom transformations.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Clean up data.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Manage tables.</source>
        </trans-unit></group></body></file></xliff>