<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="4-complete-labs-in-azure-databricks.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4-complete-labs-in-azure-databricks.0e69be.622867bdce98b13de2a9d7362fc30e92399480ee.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">622867bdce98b13de2a9d7362fc30e92399480ee</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\data-ingestion-with-azure-data-factory\includes\4-complete-labs-in-azure-databricks.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>You now have your storage account and data factory instance up and running.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Switch to your Databricks workspace to complete the rest of the workflow.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>We'll use a sample dataset to create a Data Factory pipeline and use sample notebooks to transform and analyze the data.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>To complete the following procedures, you must have already deployed your Databricks workspace in your Azure portal.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Clone the Databricks archive</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>In the Azure portal, go to your Databricks workspace and select <bpt id="p1">**</bpt>Launch workspace<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>In the left pane, select <bpt id="p1">**</bpt>Workspace<ept id="p1">**</ept>, select <bpt id="p2">**</bpt>Users<ept id="p2">**</ept>, and then select your username (the entry with the house icon).</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>In the pane that appears, select the downward-pointing chevron next to your name, and then select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>A screenshot showing the menu option to import the archive</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>In the <bpt id="p1">**</bpt>Import Notebooks<ept id="p1">**</ept> pane, select <bpt id="p2">**</bpt>URL<ept id="p2">**</ept>, and paste in the following URL:</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Select <bpt id="p1">**</bpt>Import<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>A folder named after the archive should appear.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Select that folder.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The folder contains one or more notebooks that you'll use in completing this lab.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Complete the following notebooks</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>01 Getting Started<ept id="p1">**</ept> - This notebook contains instructions for setting up your storage account and Azure Data Factory (ADF).</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>If you've already set up these in the previous unit, you can skip this notebook.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>02 Data Ingestion<ept id="p1">**</ept> - In this notebook, you create a Data Factory v2 pipeline to ingest data from a public dataset into your storage account.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>After the data is ingested, you use a Databricks notebook function to examine the data.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>03 Data Transformation<ept id="p1">**</ept> - This notebook contains instructions to create connectivity between your Azure Data Factory and Databricks workspace.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>You will add a Databricks Notebook activity to your ADF pipeline that will run a sample notebook to transform and restructure your data.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>You'll also perform some basic aggregation on the sample dataset to generate required reports.</source>
        </trans-unit></group></body></file></xliff>