<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="1-introduction.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1-introduction.7387d170ac297e3dc0fa6da04dc4c2e6f607a9b6.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">386c84a53c892ca4e9802b5f95019d41daecafd4</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\create-data-pipelines-using-databricks-delta\includes\1-introduction.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Imagine that you work in the IT department of a large retail store.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>Your organization uses Azure Data Lake to store all its online shopping data.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>However, as the volume of data increases, updating and querying information from storage is becoming more and more time consuming.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Your responsibility is to investigate the problem and find a solution.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>You need a solution that matches Data Lake in scalability but is also reliable and fast.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Databricks Delta can solve your problem.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>It's a unified data-management system that combines the best capabilities of Data Lake, data warehousing, and a streaming ingestion system.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Learning objectives</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In this module, you will:</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Use Databricks Delta to create, append, and upsert tables.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Work with streaming data.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Perform optimizations in Databricks Delta.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Implement a Lambda Architecture by processing batch and streaming data with Databricks Delta.</source>
        </trans-unit></group></body></file></xliff>