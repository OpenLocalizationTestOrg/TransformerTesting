<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="2-overview-of-databricks-delta.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">2-overview-of-databricks-delta.d808a8650f14c8f2e8c48921489329f4634aa586.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">66a4a4d1673df1ec81fd298d98e5eead9c0ddb0b</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\databricks\create-data-pipelines-using-databricks-delta\includes\2-overview-of-databricks-delta.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Databricks Delta is a transactional storage layer designed specifically to work with Apache Spark and Databricks File System (DBFS).</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>At the core of Databricks Delta is an optimized Spark table.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>It stores your data as Apache Parquet files in DBFS and maintains a transaction log that efficiently tracks changes to the table.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>The challenge with data lakes</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>A data lake is a storage repository that inexpensively stores a vast amount of raw data, both current and historical, in native formats such as XML, JSON, CSV, and Parquet.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>It may contain operational relational databases with live transactional data.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>To extract meaningful information from a data lake, you must solve problems such as:</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Schema enforcement when new tables are introduced.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Table repairs when any new data is inserted into the data lake.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Frequent refreshes of metadata.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Bottlenecks of small file sizes for distributed computations.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Difficulty sorting data by an index if data is spread across many files and partitioned.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The solution: Databricks Delta</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Databricks Delta is a Spark table with built-in reliability and performance optimizations.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>You can read and write data that's stored in Databricks Delta by using Apache Spark SQL batch and streaming APIs.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>These are the same familiar APIs that you use to work with Hive tables or DBFS directories.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Databricks Delta provides the following functionality:</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ACID transactions<ept id="p1">**</ept>: Multiple writers can simultaneously modify a dataset and see consistent views.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>DELETE, UPDATE, and UPSERT operations<ept id="p1">**</ept>: Writers can modify a dataset without interfering with jobs that read the dataset.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Automatic file management<ept id="p1">**</ept>: Data access speeds up because data is organized into large files that can be read efficiently.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Statistics and data skipping<ept id="p1">**</ept>: Reads are 10 to 100 times faster because statistics are tracked about the data in each file.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>This tracking lets Delta avoid reading irrelevant information.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Databricks Delta architecture vs. the Lambda Architecture</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Lambda Architecture</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>The Lambda Architecture is a big-data processing architecture that combines both batch and real-time processing methods.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>It features an append-only, immutable data source that serves as the system of record.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Time-stamped events are appended to existing events, and nothing is overwritten.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>Data is implicitly ordered by time of arrival.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Notice that there are really two pipelines here: one batch and one streaming.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Hence the name Lambda Architecture.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>It's difficult to combine processing of batch and real-time data, as this diagram shows:</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>A diagram of the Lambda Architecture</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Databricks Delta architecture</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>The Databricks Delta architecture is a vast improvement upon the traditional Lambda Architecture.</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Text files, RDBMS data, and streaming data are collected into a <bpt id="p1">*</bpt>raw table<ept id="p1">*</ept>, also known as a <bpt id="p2">*</bpt>bronze table<ept id="p2">*</ept> at Databricks.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>A raw table is then parsed into <bpt id="p1">*</bpt>query tables<ept id="p1">*</ept>, also known as <bpt id="p2">*</bpt>silver tables<ept id="p2">*</ept> at Databricks.</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Query tables may be joined with dimension tables.</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>Summary tables<ept id="p1">*</ept>, also known as <bpt id="p2">*</bpt>gold tables<ept id="p2">*</ept> at Databricks, are business-level aggregates.</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>They're often used for reporting, dashboards, and aggregations such as daily active website users.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The final outputs are actionable insights, dashboards, and reports of business metrics.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>A diagram of the Databricks Delta architecture</source>
        </trans-unit></group></body></file></xliff>