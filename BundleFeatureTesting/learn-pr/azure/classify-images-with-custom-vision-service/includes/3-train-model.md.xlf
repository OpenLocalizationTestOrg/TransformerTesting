<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="3-train-model.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3-train-model.9f85182772f7482c0159e098c0007992c6beee68.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">7d8dbbfd6c0fb32b3aecdf5b998929a192825c54</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\azure\classify-images-with-custom-vision-service\includes\3-train-model.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>In this unit, you'll train the model using the images uploaded and tagged in the previous exercise.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>After you train a model, you can refine it by uploading additional tagged images and retraining it.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>Click the <bpt id="p1">**</bpt>Train<ept id="p1">**</ept> button at the top of the page to train the model.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Each time you train the model, a new iteration is created.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The Custom Vision Service maintains several iterations, allowing you to compare your progress over time.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Screenshot of the top bar of the Artworks project with the Train button highlighted</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Wait for the training process to finish.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>(It should take only a few seconds.) Then review the training statistics presented to you for iteration 1.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>The results show two measures of a model's accuracy, <bpt id="p1">**</bpt>Precision<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Recall<ept id="p2">**</ept>.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Suppose the model was presented with three Picasso images and three from Van Gogh.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Let's say it correctly identified two of the Picasso samples as "Picasso" images, but incorrectly identified two of the Van Gogh samples as Picasso.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>In this case, the <bpt id="p1">**</bpt>Precision<ept id="p1">**</ept> would be 50%, since it identified two out of four images correctly.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">**</bpt>Recall<ept id="p1">**</ept> score would be 67% since it correctly identified two of the three Picasso images correctly.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Screenshot showing the results of training the model.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The results show overall 100 percent precision and 84.8 percent recall.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>In the next exercise, we'll test the model using the portal's Quick Test feature, which allows you to submit images to the model and see how it classifies them using the knowledge gained from the training images.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>In addition to training the model using the Custom Vision portal UI, you can also train it by calling the <bpt id="p1">[</bpt>TrainProject<ept id="p1">](https://southcentralus.dev.cognitive.microsoft.com/docs/services/d9a10a4a5f8549599f1ecafc435119fa/operations/58d5835bc8cb231380095bed)</ept> method in the <bpt id="p2">[</bpt>Custom Vision Training API<ept id="p2">](https://southcentralus.dev.cognitive.microsoft.com/docs/services/d9a10a4a5f8549599f1ecafc435119fa/operations/58d5835bc8cb231380095be3)</ept>.</source>
        </trans-unit></group></body></file></xliff>