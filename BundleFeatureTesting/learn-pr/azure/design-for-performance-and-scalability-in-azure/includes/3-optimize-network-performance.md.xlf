<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="3-optimize-network-performance.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff"  tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3-optimize-network-performance.91ac50.80e3657f1b87e3d373be9482aa99ca58340a69aa.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">80e3657f1b87e3d373be9482aa99ca58340a69aa</xliffext:ms.openlocfilehash><xliffext:ms.sourcegitcommit xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ba7e452ac39d7f09a5646044b44de0e1cdc54982</xliffext:ms.sourcegitcommit><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\azure\design-for-performance-and-scalability-in-azure\includes\3-optimize-network-performance.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Network performance can have a dramatic impact on a user's experience.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>In complex architectures with many different services, minimizing the latency at each hop can have a huge impact on the overall performance.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>In this unit, we'll talk about the importance of network latency and how to reduce it within your architecture.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>We'll also discuss how Lamna Healthcare adopted strategies to minimize network latency between their Azure resources as well as between their users and Azure.</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The importance of network latency</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Latency is a measure of delay.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Network latency is the time needed to get from a source to a destination across some network infrastructure.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>This time period is commonly known as a round-trip delay, or the time taken to get from the source to destination and back again.</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In a traditional datacenter environment, latency may be minimal since resources often share the same location and a common set of infrastructure.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The time taken to get from source to destination is lower when resources are physically close together.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>In comparison, a cloud environment is built for scale.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>Cloud-hosted resources may not be in the same rack, datacenter, or even region.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>This distributed approach can have an impact on the round-trip time of your network communications.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>While all Azure regions are interconnected by a high-speed fiber backbone, the speed of light is still a physical limitation.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Calls between services in different physical locations will still have network latency directly correlated to the distance between them.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>On top of this, the chattier an application, the more round trips that are required.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Each round trip comes with a latency tax, with each round trip adding to the overall latency.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The following illustration shows how the latency perceived by the user is the combination of the roundtrips required to service the request.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>An illustration showing network latency among resources placed at different geographical locations in the cloud.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Now let's take a look at how to improve performance between Azure resources and from your end users to your Azure resources.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Latency between Azure resources</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Imagine that Lamna Healthcare is piloting a new patient booking system running on several web servers and a database in the West Europe Azure region.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>This architecture minimizes the data time on the wire as resources are co-located inside an Azure region.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Suppose that the pilot of the system went well and has been expanded to users in Australia.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Users in Australia will incur the round-trip time to the resources in West Europe to view the website, and their end-user experience will be poor due to the network latency.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The Lamna Healthcare team decide to host another front-end instance in the Australia East region to reduce user latency.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>While this design helps reduce the time for the web server to return content to end users, their experience is still poor since there's significant latency communicating between the front-end web servers in Australia East and the database in West Europe.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>There are a few ways we could reduce the remaining latency:</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>Create a read-replica of the database in Australia East.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>This would allow reads to perform well, but writes would still incur latency.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Azure SQL Database geo-replication allows for read-replicas.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Sync your data between regions with Azure SQL Data Sync.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>Use a globally distributed database such as Azure Cosmos DB.</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>This would allow both reads and writes to occur regardless of location, but may require changes to the way your application stores and references data.</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>Use caching technology such as Azure Cache for Redis to minimize high-latency calls to remote databases for frequently accessed data.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>The goal here is to minimize the network latency between each layer of the application.</source>
        </trans-unit><trans-unit id="137" translate="yes" xml:space="preserve">
          <source>How this is solved depends on your application and data architecture, but Azure provides mechanisms to solve this on several services.</source>
        </trans-unit><trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Latency between users and Azure resources</source>
        </trans-unit><trans-unit id="139" translate="yes" xml:space="preserve">
          <source>We've looked at the latency between our Azure resources, but we should also consider the latency between users and our cloud application.</source>
        </trans-unit><trans-unit id="140" translate="yes" xml:space="preserve">
          <source>We're looking to optimize delivery of the front end-user interface to our users.</source>
        </trans-unit><trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Let's take a look at some ways to improve the network performance between end users and the application.</source>
        </trans-unit><trans-unit id="142" translate="yes" xml:space="preserve">
          <source>Use a DNS load balancer for endpoint path optimization</source>
        </trans-unit><trans-unit id="143" translate="yes" xml:space="preserve">
          <source>In the Lamna Healthcare example, we saw that the team created an additional web front-end node in Australia East.</source>
        </trans-unit><trans-unit id="144" translate="yes" xml:space="preserve">
          <source>However, end users have to explicitly specify which front-end endpoint they want to use.</source>
        </trans-unit><trans-unit id="145" translate="yes" xml:space="preserve">
          <source>As the designer of a solution, Lamna Healthcare wants to make the experience as smooth as possible for their users.</source>
        </trans-unit><trans-unit id="146" translate="yes" xml:space="preserve">
          <source>Azure Traffic Manager could help.</source>
        </trans-unit><trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Traffic Manager is a DNS-based load balancer that enables you to distribute traffic within and across Azure regions.</source>
        </trans-unit><trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Rather than having the user browse to a specific instance of our web front end, Traffic Manager can route users based upon a set of characteristics:</source>
        </trans-unit><trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Priority<ept id="p1">**</ept> - You specify an ordered list of front-end instances.</source>
        </trans-unit><trans-unit id="150" translate="yes" xml:space="preserve">
          <source>If the one with the highest priority is unavailable, Traffic Manager will route the user to the next available instance.</source>
        </trans-unit><trans-unit id="151" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Weighted<ept id="p1">**</ept> - You would set a weight against each front-end instance.</source>
        </trans-unit><trans-unit id="152" translate="yes" xml:space="preserve">
          <source>Traffic Manager then distributes traffic according to those defined ratios.</source>
        </trans-unit><trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Performance<ept id="p1">**</ept> - Traffic Manager routes users to the closest front-end instance based on network latency.</source>
        </trans-unit><trans-unit id="154" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Geographic<ept id="p1">**</ept> - You could set up geographical regions for front-end deployments, routing your users based upon data sovereignty mandates or localization of content.</source>
        </trans-unit><trans-unit id="155" translate="yes" xml:space="preserve">
          <source>Traffic Manager profiles can also be nested.</source>
        </trans-unit><trans-unit id="156" translate="yes" xml:space="preserve">
          <source>You could first route your users across different geographies (for example, Europe and Australia) using geographic routing and then route them to local front-end deployments using the performance routing method.</source>
        </trans-unit><trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Consider that Lamna Healthcare has deployed a web front end in West Europe and Australia.</source>
        </trans-unit><trans-unit id="158" translate="yes" xml:space="preserve">
          <source>Assume they have deployed Azure SQL Database with their primary deployment in West Europe, and a read replica in Australia East.</source>
        </trans-unit><trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Let's also assume the application can connect to the local SQL instance for read queries.</source>
        </trans-unit><trans-unit id="160" translate="yes" xml:space="preserve">
          <source>The team deploy a Traffic Manager instance in performance mode and add the two front-end instances as Traffic Manager profiles.</source>
        </trans-unit><trans-unit id="161" translate="yes" xml:space="preserve">
          <source>As an end user, you navigate to a custom domain name (for example, lamnahealthcare.com) which routes to Traffic Manager.</source>
        </trans-unit><trans-unit id="162" translate="yes" xml:space="preserve">
          <source>Traffic Manager then returns the DNS name of the West Europe or Australia East front end based on the best network latency performance.</source>
        </trans-unit><trans-unit id="163" translate="yes" xml:space="preserve">
          <source>It's important to note that this load balancing is only handled via DNS, there's no inline load balancing or caching that's happening here, Traffic Manager is simply returning the DNS name of the closest front end to the user.</source>
        </trans-unit><trans-unit id="164" translate="yes" xml:space="preserve">
          <source>Use CDN to cache content close to users</source>
        </trans-unit><trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The website will likely be using some form of static content (either whole pages or assets such as images and videos).</source>
        </trans-unit><trans-unit id="166" translate="yes" xml:space="preserve">
          <source>This content could be delivered to users faster by using a content delivery network (CDN) such as Azure CDN.</source>
        </trans-unit><trans-unit id="167" translate="yes" xml:space="preserve">
          <source>When Lamna deploys content to Azure CDN, those items are copied to multiple servers around the globe.</source>
        </trans-unit><trans-unit id="168" translate="yes" xml:space="preserve">
          <source>Let's say one of those items is a video served from blob storage: <ph id="ph1">`HowToCompleteYourBillingForms.MP4`</ph>.</source>
        </trans-unit><trans-unit id="169" translate="yes" xml:space="preserve">
          <source>The team then configure the website so that each user's link to the video will actually reference the CDN edge server nearest them, rather than referencing blob storage.</source>
        </trans-unit><trans-unit id="170" translate="yes" xml:space="preserve">
          <source>This approach puts content closer to the destination, reducing latency and improving user experience.</source>
        </trans-unit><trans-unit id="171" translate="yes" xml:space="preserve">
          <source>The following illustration shows how using Azure CDN puts content closer to the destination which reduces latency and improves the user experience.</source>
        </trans-unit><trans-unit id="172" translate="yes" xml:space="preserve">
          <source>An illustration showing usage of Azure content delivery network to reduce latency.</source>
        </trans-unit><trans-unit id="173" translate="yes" xml:space="preserve">
          <source>Content delivery networks <bpt id="p1">_</bpt>can<ept id="p1">_</ept> also be used to host cached dynamic content.</source>
        </trans-unit><trans-unit id="174" translate="yes" xml:space="preserve">
          <source>Extra consideration is required, though, since cached content may be out of date compared with the source.</source>
        </trans-unit><trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Context expiration can be controlled by setting a time to live (TTL).</source>
        </trans-unit><trans-unit id="176" translate="yes" xml:space="preserve">
          <source>If the TTL is too high, out-of-date content may be displayed and the cache would need to be purged.</source>
        </trans-unit><trans-unit id="177" translate="yes" xml:space="preserve">
          <source>One way to handle cached content is with a feature called <bpt id="p1">**</bpt>dynamic site acceleration<ept id="p1">**</ept>, which can increase performance of webpages with dynamic content.</source>
        </trans-unit><trans-unit id="178" translate="yes" xml:space="preserve">
          <source>Dynamic site acceleration can also provide a low-latency path to additional services in your solution (for example, an API endpoint).</source>
        </trans-unit><trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Use ExpressRoute for connectivity from on-premises to Azure</source>
        </trans-unit><trans-unit id="180" translate="yes" xml:space="preserve">
          <source>Optimizing network connectivity from your on-premises environment to Azure is also important.</source>
        </trans-unit><trans-unit id="181" translate="yes" xml:space="preserve">
          <source>For users connecting to applications, whether they're hosted on virtual machines or on PaaS offerings like Azure App Service, you'll want to ensure they have the best connection to your applications.</source>
        </trans-unit><trans-unit id="182" translate="yes" xml:space="preserve">
          <source>You can always use the public internet to connect users to your services, but internet performance can vary and may be impacted by outside issues.</source>
        </trans-unit><trans-unit id="183" translate="yes" xml:space="preserve">
          <source>On top of that, you may not want to expose all of your services over the internet, and you may want a private connection to your Azure resources.</source>
        </trans-unit><trans-unit id="184" translate="yes" xml:space="preserve">
          <source>Site-to-site VPN over the internet is also an option, but for high throughput architectures, VPN overhead and internet variability can increase latency noticeably.</source>
        </trans-unit><trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Azure ExpressRoute can help.</source>
        </trans-unit><trans-unit id="186" translate="yes" xml:space="preserve">
          <source>ExpressRoute is a private, dedicated connection between your network and Azure, giving you guaranteed performance and ensuring that your end users have the best path to all of your Azure resources.</source>
        </trans-unit><trans-unit id="187" translate="yes" xml:space="preserve">
          <source>The following illustration shows how ExpressRoute Circuit provides connectivity between on-premises applications and Azure resources.</source>
        </trans-unit><trans-unit id="188" translate="yes" xml:space="preserve">
          <source>An architectural diagram showing an ExpressRoute Circuit connecting the customer network with Azure resources.</source>
        </trans-unit><trans-unit id="189" translate="yes" xml:space="preserve">
          <source>Once again looking at Lamna's scenario, they decide to further improve end-user experience for users who are in their facilities by provisioning an ExpressRoute circuit in both Australia East and West Europe.</source>
        </trans-unit><trans-unit id="190" translate="yes" xml:space="preserve">
          <source>This gives their end users a direct connection to their booking system and ensures the lowest latency possible for their application.</source>
        </trans-unit><trans-unit id="191" translate="yes" xml:space="preserve">
          <source>Considering the impact of network latency on your architecture is important to ensure the best possible performance for your end users.</source>
        </trans-unit><trans-unit id="192" translate="yes" xml:space="preserve">
          <source>We've taken a look at some options to lower network latency between end users and Azure and between Azure resources.</source>
        </trans-unit></group></body></file></xliff>