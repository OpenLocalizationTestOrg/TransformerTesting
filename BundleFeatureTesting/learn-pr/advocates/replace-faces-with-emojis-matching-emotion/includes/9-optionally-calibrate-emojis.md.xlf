<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="9-optionally-calibrate-emojis.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">9-optionally-calibrate-emojis.4033f636acbf7dd660eccad29bba9363f5ec8813.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ddafc9f45385dca2cdd962f9e3496e338b4b2156</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">04/24/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\advocates\replace-faces-with-emojis-matching-emotion\includes\9-optionally-calibrate-emojis.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>You canâ€™t pass an image of the emoji to the Face API to get its emotion because it's not a human face.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>So for each emoji, you need an emotive coordinate.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>We have used a very simple method of generating emotive coordinates in the module.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>This method</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>Takes one real face with an expression approximating that of the emoji.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>We call this the proxy image.</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>Runs it through the Azure Face API</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>Uses the result of that operation as the emotive coordinates for the emoji</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source>In this unit, we demonstrate how you can substitute your own proxy images, and re-calibrate the emoji emotive coordinates.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>As an extension, you could also devise more a more rigorous method of performing this mapping, by training with many sets of images, for example.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>Proxy Images</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source>You can see the list of proxy images for each emoji in the <ph id="ph1">`shared/proxy-images`</ph> folder in the sample code.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>A set of paired images of some of the Cloud Developer Advocates making various expressive faces next to their matching mojified images.</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>These proxy images were passed to the Face API to generate emotive points, which were then associated with an emoji image.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>You can see the results of the supplied set of proxy images in the <ph id="ph1">`MOJIS`</ph> array in the <ph id="ph2">`shared/models/mojis.ts`</ph> file in the source code.</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Create your own proxy images for emojis</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>You can use your own images if you prefer.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>It can be fun to mojify yourself or your teammates at work in Slack!</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>If you plan to use your own images, then take a picture of yourself mimicking each emoji in the <ph id="ph1">`shared/proxy-images`</ph> folder and replace the original set of images.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Create an Azure function to calibrate your proxy images</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Just as you did for the <ph id="ph1">`MojifyImage`</ph> and the <ph id="ph2">`RespondToSlackCommand`</ph> function, create another function called <ph id="ph3">`Calibrate`</ph>.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Replace the index.js file with a file called index.ts, and copy the following code into this file:</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Try it out</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Now comes the fun part!</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>We are going to run each of the images in the <ph id="ph1">`shared/proxy-images`</ph> through the Face API to calculate an emotional point for that emoji in emotional space.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Make sure the function app is running by starting it from the debug menu or running it from the terminal.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>Run the new <ph id="ph1">`Calibrate`</ph> function by connecting to: <ph id="ph2">http://localhost:7071/api/Calibrate</ph>.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The Face API restricts the rate at which it can be called.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>If the rate limit is exceed the code will wait 30 seconds and try again.</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>Since the calibrate function is make calls in quick succession you may hit this rate limit, and see that the Calibrate function takes a minute or two to execute.</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>The output of the command is displayed in your browser window, as json array of emotive points.</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>You can try out different proxy images, and see the change in the emotive points.</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>You can also copy this array back into <ph id="ph1">`shared/models/mojis.ts`</ph>, redeploy your function app, so that you are using your own proxy images in your slack <ph id="ph2">`/mojify`</ph> command.</source>
        </trans-unit></group></body></file></xliff>