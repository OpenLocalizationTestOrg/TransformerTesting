<?xml version="1.0"?><xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd"><file datatype="xml" original="5-extract-printed-text.md" source-language="en-US" target-language="en-US"><header><tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-1931010" tool-company="Microsoft" /><xliffext:skl_file_name xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">5-extract-printed-text.e7f2b95702ae8872b672de23d5ebc52bb9561afe.skl</xliffext:skl_file_name><xliffext:version xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">1.2</xliffext:version><xliffext:ms.openlocfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">bf7d5135fb07a5dc000a0e889fae829bfbe4ef76</xliffext:ms.openlocfilehash><xliffext:ms.lasthandoff xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">05/13/2019</xliffext:ms.lasthandoff><xliffext:ms.openlocfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">learn-pr\advocates\create-computer-vision-service-to-classify-images\includes\5-extract-printed-text.md</xliffext:ms.openlocfilepath></header><body><group id="content" extype="content"><trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Suppose you now want to read text from the stock images that your frontline distributors post to your server.</source>
        </trans-unit><trans-unit id="102" translate="yes" xml:space="preserve">
          <source>In particular, you want to scan product looking for promotional stickers that containing sale prices.</source>
        </trans-unit><trans-unit id="103" translate="yes" xml:space="preserve">
          <source>It's time to try the optical character recognition (OCR) feature of the Computer Vision API.</source>
        </trans-unit><trans-unit id="104" translate="yes" xml:space="preserve">
          <source>Calling the Computer Vision API to extract printed text</source>
        </trans-unit><trans-unit id="105" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`ocr`</ph> operation detects text in an image and extracts the recognized characters into a machine-usable character stream.</source>
        </trans-unit><trans-unit id="106" translate="yes" xml:space="preserve">
          <source>The request URL has the following format:</source>
        </trans-unit><trans-unit id="107" translate="yes" xml:space="preserve">
          <source>As usual, all calls must be made to the region where the account was created.</source>
        </trans-unit><trans-unit id="108" translate="yes" xml:space="preserve">
          <source>The call accepts two optional parameters:</source>
        </trans-unit><trans-unit id="109" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>language<ept id="p1">**</ept>: The language code of the text to be detected in the image.</source>
        </trans-unit><trans-unit id="110" translate="yes" xml:space="preserve">
          <source>The default value is <ph id="ph1">`unk`</ph>,or unknown.</source>
        </trans-unit><trans-unit id="111" translate="yes" xml:space="preserve">
          <source>This let's the service auto detect the language of the text in the image.</source>
        </trans-unit><trans-unit id="112" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>detectOrientation<ept id="p1">**</ept>: When true, the service  tries to detect the image orientation and correct it before further processing, for example, whether the image is upside-down.</source>
        </trans-unit><trans-unit id="113" translate="yes" xml:space="preserve">
          <source>Extract printed text from an image using OCR</source>
        </trans-unit><trans-unit id="114" translate="yes" xml:space="preserve">
          <source>The image we're going to be using for Optical Character Recognition (OCR) is the cover from the book <bpt id="p1">*</bpt>.NET Microservices: Architecture for Containerized .NET Applications<ept id="p1">*</ept>.</source>
        </trans-unit><trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Picture of the cover of the ebook .NET Microservices: Architecture for containerized .NET Application</source>
        </trans-unit><trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Execute the following command in Cloud Shell.</source>
        </trans-unit><trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Replace <ph id="ph1">`&lt;region&gt;`</ph> in the command with the region of your cognitive services account.</source>
        </trans-unit><trans-unit id="118" translate="yes" xml:space="preserve">
          <source>The following JSON is an example of the response we get from this call.</source>
        </trans-unit><trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Some lines of JSON have been removed to make the snippet fit better on the page.</source>
        </trans-unit><trans-unit id="120" translate="yes" xml:space="preserve">
          <source>Let's examine this response in more detail.</source>
        </trans-unit><trans-unit id="121" translate="yes" xml:space="preserve">
          <source>The service identified the text as being English.</source>
        </trans-unit><trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The value of the <ph id="ph1">`language`</ph> field contains the BCP-47 language code of the text detected in the image.</source>
        </trans-unit><trans-unit id="123" translate="yes" xml:space="preserve">
          <source>In this example it is <bpt id="p1">**</bpt>en<ept id="p1">**</ept>, or English.</source>
        </trans-unit><trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`orientation`</ph> was detected as <bpt id="p1">**</bpt>up<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="125" translate="yes" xml:space="preserve">
          <source>This property is the direction that the top of the recognized text is facing, after the image has been rotated around its center according to the detected text angle.</source>
        </trans-unit><trans-unit id="126" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`textAngle`</ph> is the angle by which the text must be rotated to become horizontal or vertical.</source>
        </trans-unit><trans-unit id="127" translate="yes" xml:space="preserve">
          <source>In this example, the text was perfectly horizontal, so the value returned is <bpt id="p1">**</bpt>0<ept id="p1">**</ept>.</source>
        </trans-unit><trans-unit id="128" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">`regions`</ph> property contains a list of values used to show where the text is, its position in the picture, and the word found in that part of the image.</source>
        </trans-unit><trans-unit id="129" translate="yes" xml:space="preserve">
          <source>The four integers of the <ph id="ph1">`boundingBox`</ph> value are:</source>
        </trans-unit><trans-unit id="130" translate="yes" xml:space="preserve">
          <source>the x-coordinate of the left edge</source>
        </trans-unit><trans-unit id="131" translate="yes" xml:space="preserve">
          <source>the y-coordinate of the top edge</source>
        </trans-unit><trans-unit id="132" translate="yes" xml:space="preserve">
          <source>the width of the bounding box</source>
        </trans-unit><trans-unit id="133" translate="yes" xml:space="preserve">
          <source>the height of the bounding box,</source>
        </trans-unit><trans-unit id="134" translate="yes" xml:space="preserve">
          <source>You can use these values to draw boxes around every piece of text found in the image.</source>
        </trans-unit><trans-unit id="135" translate="yes" xml:space="preserve">
          <source>As you can see in this exercise, the <ph id="ph1">`ocr`</ph> service gives detailed information about the printed text in an image.</source>
        </trans-unit><trans-unit id="136" translate="yes" xml:space="preserve">
          <source>For more information about the <ph id="ph1">`ocr`</ph> operation, see the <bpt id="p1">[</bpt>OCR<ept id="p1">](https://westus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fc)</ept> reference documentation.</source>
        </trans-unit></group></body></file></xliff>